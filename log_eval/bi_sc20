Arguments:
data_path                     ./data
checkpoint_path               ./checkpoints
log_step                      10
num_workers                   4
disable_cuda                  False
cuda_device                   0
torch_seed                    10765677988286053325
model                         gve
dataset                       iu
pretrained_model              resnet50
layers_to_truncate            1
sc_ckpt                       ./data/iu/sentence_classifier_ckpt.pth
weights_ckpt                  None
loss_lambda                   0.2
embedding_size                1000
hidden_size                   1000
num_epochs                    30
batch_size                    128
learning_rate                 0.001
train                         True
eval_ckpt                     None

Preparing Data ...
loading annotations into memory...
Done (t=0.05s)
creating index...
index created!
loading annotations into memory...
Done (t=0.00s)
creating index...
index created!

Loading Model ...
embed_size: 1000
GVE(
  (vision_model): PretrainedModel(
    (pretrained_model): Sequential(
      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace)
      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace)
        )
      )
      (5): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace)
        )
      )
      (6): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace)
        )
      )
      (7): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace)
        )
      )
      (8): AdaptiveAvgPool2d(output_size=(1, 1))
    )
  )
  (word_embed): Embedding(978, 1000, padding_idx=0)
  (linear1): Linear(in_features=2048, out_features=1000, bias=True)
  (lstm1): LSTM(1000, 1000, batch_first=True)
  (lstm2): LSTM(2017, 1000, batch_first=True)
  (linear2): Linear(in_features=1000, out_features=978, bias=True)
  (sentence_classifier): SentenceClassifier(
    (word_embed): Embedding(978, 1000, padding_idx=0)
    (lstm): LSTM(1000, 2000, batch_first=True, bidirectional=True)
    (linear): Linear(in_features=4000, out_features=17, bias=True)
  )
) 

Training ...
Epoch [0/30], Step [0/23], Loss: 11.2884, Perplexity: 79891.0990
Epoch [0/30], Step [10/23], Loss: 5.0448, Perplexity: 155.2139
Epoch [0/30], Step [20/23], Loss: 4.7412, Perplexity: 114.5760
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ting index...
index created!
tokenization...
setting up scorers...
computing Bleu score...
{'testlen': 18250, 'reflen': 10832, 'guess': [18250, 17885, 17520, 17155], 'correct': [2651, 792, 370, 113]}
ratio: 1.684822747414911
Bleu_1: 0.145
Bleu_2: 0.080
Bleu_3: 0.051
Bleu_4: 0.031
computing METEOR score...
METEOR: 0.086
computing Rouge score...
ROUGE_L: 0.163
computing CIDEr score...
CIDEr: 0.001
dict_items([('Bleu_1', 0.14526027397259478), ('Bleu_2', 0.08020317259906887), ('Bleu_3', 0.05140636625184604), ('Bleu_4', 0.03075633692779699), ('METEOR', 0.08631986770950659), ('ROUGE_L', 0.1630754240514426), ('CIDEr', 0.0006898210690678906)])
Epoch [18/30], Step [0/23], Loss: 0.7934, Perplexity: 2.2108
Epoch [18/30], Step [10/23], Loss: 0.8647, Perplexity: 2.3743
Epoch [18/30], Step [20/23], Loss: 0.8765, Perplexity: 2.4025
Epoch [18/30], Step [0/3]
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
tokenization...
setting up scorers...
computing Bleu score...
{'testlen': 18250, 'reflen': 10832, 'guess': [18250, 17885, 17520, 17155], 'correct': [2651, 868, 428, 192]}
ratio: 1.684822747414911
Bleu_1: 0.145
Bleu_2: 0.084
Bleu_3: 0.056
Bleu_4: 0.037
computing METEOR score...
METEOR: 0.087
computing Rouge score...
ROUGE_L: 0.163
computing CIDEr score...
CIDEr: 0.001
dict_items([('Bleu_1', 0.14526027397259478), ('Bleu_2', 0.083963168639031), ('Bleu_3', 0.05563683745882198), ('Bleu_4', 0.037260566480259195), ('METEOR', 0.08722580324703762), ('ROUGE_L', 0.1630754240514426), ('CIDEr', 0.000734724174426066)])
Epoch [19/30], Step [0/23], Loss: 0.8641, Perplexity: 2.3729
Epoch [19/30], Step [10/23], Loss: 0.7699, Perplexity: 2.1596
Epoch [19/30], Step [20/23], Loss: 0.7196, Perplexity: 2.0537
Epoch [19/30], Step [0/3]
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
tokenization...
setting up scorers...
computing Bleu score...
{'testlen': 17530, 'reflen': 10832, 'guess': [17530, 17165, 16800, 16435], 'correct': [2996, 1048, 509, 233]}
ratio: 1.618353028064843
Bleu_1: 0.171
Bleu_2: 0.102
Bleu_3: 0.068
Bleu_4: 0.046
computing METEOR score...
METEOR: 0.101
computing Rouge score...
ROUGE_L: 0.183
computing CIDEr score...
CIDEr: 0.034
dict_items([('Bleu_1', 0.17090701654305926), ('Bleu_2', 0.10215007360665661), ('Bleu_3', 0.06812323910201179), ('Bleu_4', 0.04601167253526628), ('METEOR', 0.10127988095983331), ('ROUGE_L', 0.18290059648055798), ('CIDEr', 0.03387221452762901)])
Epoch [20/30], Step [0/23], Loss: 0.7926, Perplexity: 2.2091
Epoch [20/30], Step [10/23], Loss: 0.7850, Perplexity: 2.1924
Epoch [20/30], Step [20/23], Loss: 0.9479, Perplexity: 2.5804
Epoch [20/30], Step [0/3]
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
tokenization...
setting up scorers...
computing Bleu score...
{'testlen': 18250, 'reflen': 10832, 'guess': [18250, 17885, 17520, 17155], 'correct': [2404, 837, 397, 158]}
ratio: 1.684822747414911
Bleu_1: 0.132
Bleu_2: 0.079
Bleu_3: 0.052
Bleu_4: 0.034
computing METEOR score...
METEOR: 0.079
computing Rouge score...
ROUGE_L: 0.159
computing CIDEr score...
CIDEr: 0.001
dict_items([('Bleu_1', 0.13172602739725306), ('Bleu_2', 0.0785152565376271), ('Bleu_3', 0.051886555110357654), ('Bleu_4', 0.033678886118128346), ('METEOR', 0.07938428677298973), ('ROUGE_L', 0.15863739083558676), ('CIDEr', 0.0008950681395696404)])
Epoch [21/30], Step [0/23], Loss: 0.8932, Perplexity: 2.4430
Epoch [21/30], Step [10/23], Loss: 0.8653, Perplexity: 2.3757
Epoch [21/30], Step [20/23], Loss: 0.8824, Perplexity: 2.4166
Epoch [21/30], Step [0/3]
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
tokenization...
setting up scorers...
computing Bleu score...
{'testlen': 16079, 'reflen': 10832, 'guess': [16079, 15714, 15349, 14984], 'correct': [2990, 1071, 471, 184]}
ratio: 1.4843980797635261
Bleu_1: 0.186
Bleu_2: 0.113
Bleu_3: 0.073
Bleu_4: 0.047
computing METEOR score...
METEOR: 0.106
computing Rouge score...
ROUGE_L: 0.195
computing CIDEr score...
CIDEr: 0.055
dict_items([('Bleu_1', 0.1859568381118113), ('Bleu_2', 0.11257901319810842), ('Bleu_3', 0.07299367542152851), ('Bleu_4', 0.04674782813345627), ('METEOR', 0.10596126968579694), ('ROUGE_L', 0.19472649887607), ('CIDEr', 0.05451283041922528)])
Epoch [22/30], Step [0/23], Loss: 0.7766, Perplexity: 2.1741
Epoch [22/30], Step [10/23], Loss: 0.6053, Perplexity: 1.8318
Epoch [22/30], Step [20/23], Loss: 0.7380, Perplexity: 2.0918
Epoch [22/30], Step [0/3]
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
tokenization...
setting up scorers...
computing Bleu score...
{'testlen': 17930, 'reflen': 10832, 'guess': [17930, 17565, 17200, 16835], 'correct': [2563, 908, 423, 167]}
ratio: 1.6552806499259918
Bleu_1: 0.143
Bleu_2: 0.086
Bleu_3: 0.057
Bleu_4: 0.037
computing METEOR score...
METEOR: 0.086
computing Rouge score...
ROUGE_L: 0.167
computing CIDEr score...
CIDEr: 0.018
dict_items([('Bleu_1', 0.14294478527606563), ('Bleu_2', 0.08596130608967814), ('Bleu_3', 0.05664209531662753), ('Bleu_4', 0.03664209703533254), ('METEOR', 0.08551137436742748), ('ROUGE_L', 0.16689803191660668), ('CIDEr', 0.01801752420756997)])
Epoch [23/30], Step [0/23], Loss: 0.6033, Perplexity: 1.8281
Epoch [23/30], Step [10/23], Loss: 0.5355, Perplexity: 1.7082
Epoch [23/30], Step [20/23], Loss: 0.6368, Perplexity: 1.8905
Epoch [23/30], Step [0/3]
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
tokenization...
setting up scorers...
computing Bleu score...
{'testlen': 16613, 'reflen': 10832, 'guess': [16613, 16248, 15883, 15518], 'correct': [3338, 1150, 500, 216]}
ratio: 1.5336964549481598
Bleu_1: 0.201
Bleu_2: 0.119
Bleu_3: 0.076
Bleu_4: 0.050
computing METEOR score...
METEOR: 0.119
computing Rouge score...
ROUGE_L: 0.207
computing CIDEr score...
CIDEr: 0.069
dict_items([('Bleu_1', 0.20092698489133803), ('Bleu_2', 0.11925266648125421), ('Bleu_3', 0.07649937527723918), ('Bleu_4', 0.04996293210914756), ('METEOR', 0.11897349214018003), ('ROUGE_L', 0.2073713467545542), ('CIDEr', 0.06893681423291038)])
Epoch [24/30], Step [0/23], Loss: 0.6376, Perplexity: 1.8920
Epoch [24/30], Step [10/23], Loss: 0.6962, Perplexity: 2.0061
Epoch [24/30], Step [20/23], Loss: 0.6339, Perplexity: 1.8849
Epoch [24/30], Step [0/3]
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
tokenization...
setting up scorers...
computing Bleu score...
{'testlen': 18250, 'reflen': 10832, 'guess': [18250, 17885, 17520, 17155], 'correct': [2740, 906, 436, 197]}
ratio: 1.684822747414911
Bleu_1: 0.150
Bleu_2: 0.087
Bleu_3: 0.057
Bleu_4: 0.038
computing METEOR score...
METEOR: 0.091
computing Rouge score...
ROUGE_L: 0.168
computing CIDEr score...
CIDEr: 0.001
dict_items([('Bleu_1', 0.15013698630136163), ('Bleu_2', 0.08720943515171663), ('Bleu_3', 0.05741514221410301), ('Bleu_4', 0.03839624105995023), ('METEOR', 0.09128940323429746), ('ROUGE_L', 0.16831324451245272), ('CIDEr', 0.0008476456728754282)])
Epoch [25/30], Step [0/23], Loss: 0.6143, Perplexity: 1.8484
Epoch [25/30], Step [10/23], Loss: 0.6311, Perplexity: 1.8797
Epoch [25/30], Step [20/23], Loss: 0.6938, Perplexity: 2.0013
Epoch [25/30], Step [0/3]
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
tokenization...
setting up scorers...
computing Bleu score...
{'testlen': 18250, 'reflen': 10832, 'guess': [18250, 17885, 17520, 17155], 'correct': [2740, 906, 436, 197]}
ratio: 1.684822747414911
Bleu_1: 0.150
Bleu_2: 0.087
Bleu_3: 0.057
Bleu_4: 0.038
computing METEOR score...
METEOR: 0.091
computing Rouge score...
ROUGE_L: 0.168
computing CIDEr score...
CIDEr: 0.001
dict_items([('Bleu_1', 0.15013698630136163), ('Bleu_2', 0.08720943515171663), ('Bleu_3', 0.05741514221410301), ('Bleu_4', 0.03839624105995023), ('METEOR', 0.09128940323429746), ('ROUGE_L', 0.16831324451245272), ('CIDEr', 0.0008476456728754282)])
Epoch [26/30], Step [0/23], Loss: 0.5379, Perplexity: 1.7124
Epoch [26/30], Step [10/23], Loss: 0.6823, Perplexity: 1.9784
Epoch [26/30], Step [20/23], Loss: 0.7111, Perplexity: 2.0363
Epoch [26/30], Step [0/3]
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
tokenization...
setting up scorers...
computing Bleu score...
{'testlen': 18250, 'reflen': 10832, 'guess': [18250, 17885, 17520, 17155], 'correct': [2686, 894, 435, 203]}
ratio: 1.684822747414911
Bleu_1: 0.147
Bleu_2: 0.086
Bleu_3: 0.057
Bleu_4: 0.038
computing METEOR score...
METEOR: 0.091
computing Rouge score...
ROUGE_L: 0.166
computing CIDEr score...
CIDEr: 0.001
dict_items([('Bleu_1', 0.14717808219177275), ('Bleu_2', 0.08577206320125598), ('Bleu_3', 0.05673908000534116), ('Bleu_4', 0.03834317274095348), ('METEOR', 0.09092768558016312), ('ROUGE_L', 0.16628935023739053), ('CIDEr', 0.0008228130906362065)])
Epoch [27/30], Step [0/23], Loss: 0.6931, Perplexity: 1.9998
Epoch [27/30], Step [10/23], Loss: 0.6109, Perplexity: 1.8420
Epoch [27/30], Step [20/23], Loss: 0.6734, Perplexity: 1.9608
Epoch [27/30], Step [0/3]
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
tokenization...
setting up scorers...
computing Bleu score...
{'testlen': 18106, 'reflen': 10832, 'guess': [18106, 17741, 17376, 17011], 'correct': [2486, 879, 415, 164]}
ratio: 1.6715288035448974
Bleu_1: 0.137
Bleu_2: 0.082
Bleu_3: 0.055
Bleu_4: 0.035
computing METEOR score...
METEOR: 0.082
computing Rouge score...
ROUGE_L: 0.163
computing CIDEr score...
CIDEr: 0.010
dict_items([('Bleu_1', 0.13730255164033264), ('Bleu_2', 0.08247924820674449), ('Bleu_3', 0.05456689291829061), ('Bleu_4', 0.03537735991353376), ('METEOR', 0.08237515544266713), ('ROUGE_L', 0.16289475077300045), ('CIDEr', 0.00953472558440184)])
Epoch [28/30], Step [0/23], Loss: 0.6686, Perplexity: 1.9514
Epoch [28/30], Step [10/23], Loss: 0.6878, Perplexity: 1.9893
Epoch [28/30], Step [20/23], Loss: 0.6745, Perplexity: 1.9630
Epoch [28/30], Step [0/3]
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
tokenization...
setting up scorers...
computing Bleu score...
{'testlen': 17247, 'reflen': 10832, 'guess': [17247, 16882, 16517, 16152], 'correct': [3578, 1287, 662, 316]}
ratio: 1.5922267355980804
Bleu_1: 0.207
Bleu_2: 0.126
Bleu_3: 0.086
Bleu_4: 0.059
computing METEOR score...
METEOR: 0.124
computing Rouge score...
ROUGE_L: 0.208
computing CIDEr score...
CIDEr: 0.101
dict_items([('Bleu_1', 0.20745636922362107), ('Bleu_2', 0.12575947391131018), ('Bleu_3', 0.0859018957257198), ('Bleu_4', 0.059342693597452784), ('METEOR', 0.12445540197852817), ('ROUGE_L', 0.20831258187315368), ('CIDEr', 0.10059375074765163)])
Epoch [29/30], Step [0/23], Loss: 0.5668, Perplexity: 1.7626
Epoch [29/30], Step [10/23], Loss: 0.6548, Perplexity: 1.9247
Epoch [29/30], Step [20/23], Loss: 0.6623, Perplexity: 1.9393
Epoch [29/30], Step [0/3]
Loading and preparing results...
DONE (t=0.00s)
creating index...
index created!
tokenization...
setting up scorers...
computing Bleu score...
{'testlen': 18250, 'reflen': 10832, 'guess': [18250, 17885, 17520, 17155], 'correct': [2688, 893, 429, 188]}
ratio: 1.684822747414911
Bleu_1: 0.147
Bleu_2: 0.086
Bleu_3: 0.056
Bleu_4: 0.037
computing METEOR score...
METEOR: 0.089
computing Rouge score...
ROUGE_L: 0.167
computing CIDEr score...
CIDEr: 0.001
dict_items([('Bleu_1', 0.14728767123286865), ('Bleu_2', 0.08575598803243276), ('Bleu_3', 0.056469945264510595), ('Bleu_4', 0.03748045088934455), ('METEOR', 0.08928070224822363), ('ROUGE_L', 0.16669647085554468), ('CIDEr', 0.0008071121779105698)])
